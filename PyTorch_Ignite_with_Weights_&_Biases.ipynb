{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Ignite with Weights & Biases",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seankudg/Hello_World/blob/master/PyTorch_Ignite_with_Weights_%26_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztVifsYAmnRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install packages\n",
        "! pip install wandb -q\n",
        "! pip install pytorch-ignite -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPpUJQ97mp88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define network\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "import wandb\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "def get_data_loaders(train_batch_size, val_batch_size):\n",
        "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "    train_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
        "                              batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    val_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),\n",
        "                            batch_size=val_batch_size, shuffle=False)\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n",
        "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
        "    model = Net()\n",
        "    wandb.watch(model)\n",
        "    device = 'cpu'\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda'\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n",
        "    evaluator = create_supervised_evaluator(model,\n",
        "                                            metrics={'accuracy': Accuracy(),\n",
        "                                                     'nll': Loss(F.nll_loss)},\n",
        "                                            device=device)\n",
        "\n",
        "    desc = \"ITERATION - loss: {:.2f}\"\n",
        "    pbar = tqdm(\n",
        "        initial=0, leave=False, total=len(train_loader),\n",
        "        desc=desc.format(0)\n",
        "    )\n",
        "\n",
        "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
        "    def log_training_loss(engine):\n",
        "        pbar.desc = desc.format(engine.state.output)\n",
        "        pbar.update(log_interval)\n",
        "        wandb.log({\"train loss\": engine.state.output})\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_results(engine):\n",
        "        pbar.refresh()\n",
        "        evaluator.run(train_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_accuracy = metrics['accuracy']\n",
        "        avg_nll = metrics['nll']\n",
        "        tqdm.write(\n",
        "            \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "            .format(engine.state.epoch, avg_accuracy, avg_nll)\n",
        "        )\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(engine):\n",
        "        evaluator.run(val_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_accuracy = metrics['accuracy']\n",
        "        avg_nll = metrics['nll']\n",
        "        tqdm.write(\n",
        "            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "            .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
        "\n",
        "        pbar.n = pbar.last_print_n = 0\n",
        "        wandb.log({\"validation loss\": avg_nll})\n",
        "        wandb.log({\"validation accuracy\": avg_accuracy})\n",
        "\n",
        "    trainer.run(train_loader, max_epochs=epochs)\n",
        "    pbar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDbxhVw_j50G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Model\n",
        "\n",
        "hyperparameter_defaults = dict(\n",
        "    batch_size = 32,\n",
        "    val_batch_size = 100,\n",
        "    epochs = 20,\n",
        "    lr = 0.001,\n",
        "    momentum = 0.1,\n",
        "    log_interval = 10,\n",
        ")\n",
        "\n",
        "# Get metrics in Weights & Biases\n",
        "wandb.init(config=hyperparameter_defaults, project=\"pytorch-ignite-example\")\n",
        "config = wandb.config\n",
        "run(config.batch_size, config.val_batch_size, config.epochs, config.lr, config.momentum, config.log_interval)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}